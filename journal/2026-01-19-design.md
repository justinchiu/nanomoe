Started initial design brainstorm. Simplify everything around one batch contract.

---

## Simplified API (current)

- Single batch contract: `PackedBatch`.
- All data sources (pretrain/SFT/RL) yield `PackedBatch`.
- Training loop consumes `PackedBatch` only; loss uses `token_weights`.

```python
@dataclass
class PackedBatch:
    tokens: Tensor
    position_ids: Tensor
    cu_seqlens: Tensor
    token_weights: Tensor        # per-token weight (mask/advantage)
    labels: Tensor | None = None
    log_probs: Tensor | None = None
    rewards: Tensor | None = None

class BatchSource(Protocol):
    def __iter__(self) -> Iterator[PackedBatch]: ...
```

---

## Task mappings

### Pretrain

- `token_weights = 1`
- `labels = shift(tokens)`
- Dataset yields packed batches directly.

### SFT

- `token_weights = loss_mask`
- `labels = shift(tokens)`
- Dataset yields packed batches directly.

### RL

```python
class Sampler(Protocol):
    def sample_and_score(self, prompt: Tensor) -> ScoredGroup: ...

@dataclass
class ScoredGroup:
    tokens: Tensor    # [N, seq_len]
    log_probs: Tensor # [N, gen_len]
    rewards: Tensor   # [N]
    prompt_len: int

class RLDataset:
    def __iter__(self) -> Iterator[PackedBatch]: ...
```

- `RLDataset` pulls groups, filters `reward_std <= eps`, computes advantages.
- `token_weights = advantages * mask`
- Guard with `max_attempts` to avoid infinite loops.
- Metrics: `zero_var_groups`, `valid_groups`, `attempts_per_batch`.

---

## Single-node focus

- Start dense (`num_experts=1` or DenseFFN), then scale experts on one H100.
- Keep APIs stable for later DDP on a single node.
- Favor bf16 + short iterations for fast experiments.
- Use a much smaller Qwen3-30B-A3B-style MoE architecture.

---

## Sampler, logging, checkpointing

- Sampler is stateless; `RLDataset` pulls, filters, computes advantages, packs.
- Prefer sync pull loop; add queue only if sampling is the bottleneck.
- Logging in training loop: `train/*`, `rollout/*`, `perf/*`.
- Checkpoint `data_state` (streaming epoch/samples_seen; RL skip stats + RNG if needed).
