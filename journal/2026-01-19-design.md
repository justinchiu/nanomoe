Started initial design brainstorm with claude. Had it look at slime, megatron, nmoe, tinker.
Initial design untested and extremely messy.
Initial vibecode of tests.

---

## Current State Analysis (AI-generated)

### Module Structure

```
src/nanomoe/
├── data/
│   ├── types.py          # Sample, PackedBatch, SampleOutput
│   ├── packing.py        # pack_sequences, unpack_batch, get_seqlen_balanced_partitions
│   ├── buffer.py         # DataBuffer (streaming/rollout/hybrid)
│   └── packed_dataset.py # PackedPretrainDataset, create_document_mask
├── sample/
│   └── generate.py       # generate(), top_p_sample, top_k_sample, SamplingMetrics
├── train/
│   ├── grpo.py           # GRPOConfig, GRPOTrainer, grpo_loss, compute_grpo_advantages
│   ├── checkpoint.py     # Checkpointer
│   ├── logging.py        # ConsoleLogger, FileLogger, WandbLogger, CompositeLogger
│   └── lr_scheduler.py   # WSDScheduler, CosineScheduler, ConstantScheduler
├── model/
│   ├── config.py         # MoEConfig with presets (tiny, small, medium, large)
│   ├── attention.py      # RoPE, Attention (GQA)
│   ├── moe.py            # SwiGLU, Expert, TopKRouter, MoELayer, DenseFFN
│   └── model.py          # RMSNorm, TransformerBlock, MoETransformer, create_model
scripts/
└── pretrain.py           # Full pretraining loop (inline)
```

---

## Issues (AI-generated)

### 1. Data: Inconsistent Batch Types

Two different `PackedBatch` classes exist:

**`data/types.py:PackedBatch`** (for GRPO):
```python
@dataclass
class PackedBatch:
    tokens: Tensor
    loss_mask: Tensor
    position_ids: Tensor
    cu_seqlens: Tensor
    log_probs: Tensor      # RL-specific
    advantages: Tensor     # RL-specific
    rewards: Tensor        # RL-specific
```

**`data/packed_dataset.py:PackedBatch`** (for pretrain):
```python
@dataclass
class PackedBatch:
    input_ids: Tensor
    labels: Tensor
    position_ids: Tensor
    loss_mask: Tensor
    cu_seqlens: Tensor
    num_docs: int
```

Exported as `PackedBatch` vs `PretrainBatch`. Confusing naming, fields don't align.

### 2. Data: DataBuffer Does Too Much

`DataBuffer` handles three modes:
- `streaming`: Pull from HuggingFace dataset
- `rollout`: Push/pop rollout samples for GRPO
- `hybrid`: Mix of both

Violates single responsibility. Rollout buffer is fundamentally different from streaming dataset.

### 3. Data: No Clear Dataset Protocol

No standard interface for "something you iterate to get batches":
- `PackedPretrainDataset`: iterable with `__iter__` and `stop()`
- `DataBuffer`: `get_batch(batch_size, mode)` method
- `pack_sequences`: returns `list[PackedBatch]` from list of samples

Each has different semantics.

### 4. Training: Loop Lives in Script

`scripts/pretrain.py` contains ~200 lines of training loop logic:
- Gradient accumulation
- Mixed precision (GradScaler)
- Logging every N steps
- Checkpointing every N steps
- Resume from checkpoint

Should be reusable across pretrain/SFT/GRPO.

### 5. Training: GRPOTrainer is Incomplete

`GRPOTrainer.train_step()` handles one batch but:
- No outer training loop
- No checkpointing integration
- No logging integration
- No LR scheduler integration

### 6. Sampling: Assumes HuggingFace Interface

`generate()` assumes:
```python
outputs.logits        # attribute access
outputs.past_key_values
```

Our `MoETransformer` returns:
```python
outputs["logits"]     # dict access
outputs["past_key_values"]
```

### 7. Sampling: Too Many Intermediate Representations

`samples_to_grpo_batch()` converts `SampleOutput` → `list[Sample]`
`pack_sequences()` converts `list[Sample]` → `list[PackedBatch]`
`compute_grpo_advantages()` mutates `list[Sample]` in place

### 8. Model: torch.compile Breaks Type Safety

`torch.compile(model)` returns `MoETransformer | ((...) -> Unknown)`, not `MoETransformer`.

Current workaround in `pretrain.py`:
```python
model = create_model(config)
model_for_checkpoint = model  # Keep typed reference

if compile:
    compiled_model = torch.compile(model)  # Returns union type
else:
    compiled_model = model

# Use compiled_model for forward pass (typed as Any)
# Use model_for_checkpoint for checkpointer.save() (typed as MoETransformer)
```

Problems:
- Need two references to the same model
- `compiled_model` typed as `Any` loses all type safety
- Checkpointer, optimizer, etc. need the original typed model
- Easy to accidentally use wrong reference

---

## Open Questions (AI-generated)

### Q1: Batch Type Hierarchy

**Option A: Inheritance** - RLBatch extends TokenBatch
**Option B: Separate Types** - No coupling, but duplication
**Option C: Composition** - `RLBatch.base: TokenBatch`

### Q2: Where Does Packing Happen?

**Option A: Dataset yields packed batches** (current for pretrain)
**Option B: Dataset yields samples, separate packer** (current-ish for GRPO)

### Q3: Model Output Interface

**Option A: Dict** (current MoETransformer)
**Option B: Dataclass** (IDE support)
**Option C: HuggingFace compatible**

### Q4: Trainer Abstraction

**Option A: Protocol-based** - `train_loop(trainer, dataset, ...)`
**Option B: Base class** - `BaseTrainer.train()` with abstract `train_step()`
**Option C: Functional** - `train_loop(step_fn, model, optimizer, dataset, ...)`

### Q5: Sampler Ownership

**Option A: Sampler owns model** - Can manage state, but exclusive
**Option B: Sampler receives model** - Flexible, but stateless

### Q6: Handling torch.compile

**Option A: Wrapper class**
```python
class CompiledModel:
    def __init__(self, model: MoETransformer, compile: bool):
        self.model = model
        self._compiled = torch.compile(model) if compile else model

    def __call__(self, **kwargs):
        return self._compiled(**kwargs)

    # Delegate state_dict, parameters, etc. to self.model
```

**Option B: Always use Any** - Accept loss of type safety for compiled models

**Option C: Protocol for "something callable that returns ModelOutput"**
```python
class ForwardFn(Protocol):
    def __call__(self, input_ids, ...) -> ModelOutput: ...
```
