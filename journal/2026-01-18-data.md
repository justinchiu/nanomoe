# Data selection
Looked at Deepmath, Openthoughts, and Nemo-math.
Deepmath looks suitable for SFT, and Nemo-math looks suitable for pretraining.
Openthoughts is not suitable due to QWQ being too verbose.

I think we can pretty much get by with 8k max context length for both.
Nemo-math is quite short -- majority seems to be less than 4k.

Data exploration script in `scripts/explore_math_data.py`.
Plots in `plots/*_length_distribution.pdf`.
