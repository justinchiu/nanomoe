# Prefetcher
Goal: add a general device prefetcher to overlap H2D copy with compute.

## Why
- Pretrain path currently does blocking `batch.to(device)` inside `compute_loss`.
- Dataset prefetching is CPU-only, so H2D transfer can stall the step.

## Plan
1) Add a reusable prefetcher that wraps any `Iterator[PackedBatch]`.
2) Use pinned memory + `non_blocking=True` and a CUDA stream when on GPU.
3) Integrate into `train_loop` behind an optional flag (no behavior change by default).
4) Enable in pretrain experiment and expose simple config knobs (prefetch depth, pin, stream).

## Notes
- Keep it generic so SFT/RL can reuse the same wrapper.
- Avoid extra copies when batch is already on the target device.
- HF streaming `.shard()` uses `IterableDataset._ex_iterable.shard_data_sources(...)` and defaults to `contiguous=True`.
  - For DDP round-robin sharding, use `contiguous=False`.
  - Docstring says shard before any randomizing op like `shuffle`.

## Design choices
- One-batch lookahead prefetcher with a dedicated CUDA stream.
- `wait_stream` + `record_stream` on the current stream for safe async H2D.
- Prefetcher is per-rank (DDP) and only moves input tensors; FSDP behavior unchanged.
- Prefetch is CUDA-only; CPU/MPS falls back to the normal path.
- `PackedBatch.to` accepts `non_blocking` + `pin_memory` for transfer hooks.

## Profiling plan
1) Add optional profiling CLI flags to `pretrain` (enable, start_step, profile_steps, out_dir).
2) Wire NVTX ranges in `train_loop` around data_fetch, forward_backward, optimizer_step.
3) Start/stop `torch.cuda.profiler` based on the step window so `nsys` can use `--capture-range=cudaProfilerApi`.
4) Document the one-liner `nsys profile` command for prefetch on/off runs.
